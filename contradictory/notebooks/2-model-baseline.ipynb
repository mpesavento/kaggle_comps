{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04f0395-7e7d-4879-93da-fa0be5e7b1ea",
   "metadata": {},
   "source": [
    "# Contradictory sentences - baseline model\n",
    "Create a baseline model for contradiction classification\n",
    "\n",
    "Because this dataset is multi-lingual, we need to choose the best in class language model that is readily trainable (on kaggle TPUs?). One possibility is the [`XLM-RoBERTa`](https://huggingface.co/tomaarsen/span-marker-xlm-roberta-base-multinerd) model, but this model has fallen out of favor due to major tokenization limitations. The preferred model for multilanguage NER is this SpanMarker model using xlm-roberta-base as the underlying encoder, trained on the multinerd dataset: [`span-marker-xlm-roberta-base-multinerd`](https://huggingface.co/tomaarsen/span-marker-xlm-roberta-base-multinerd). The problem is that I wont want to be doing NER, I want to be doing sentence comparison.\n",
    "\n",
    "A reasonable starting point is just the base [`XLM-RoBERTa`](https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/xlm-roberta) model.\n",
    "\n",
    "This kaggle challenge was started as a reason to learn to use TPUs. You can use TPUs in PyTorch with the [`torch_xla`](https://pytorch.org/xla/release/2.0/index.html) package. See how to use it in this example kaggle code [here](https://www.kaggle.com/code/tanlikesmath/the-ultimate-pytorch-tpu-tutorial-jigsaw-xlm-r).  \n",
    "For now, we will stick with CPU/GPU. Double check Apple silicon MPS devices [[ref]](https://developer.apple.com/metal/pytorch/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717ed62d-39f5-44bd-b369-3e38749c5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "DATA_PATH = \"data\"\n",
    "WANDB_PROJECT = \"contradictory\"\n",
    "RAW_DATA_AT = \"contra_raw\"\n",
    "PROCESSED_DATA_AT = \"contra_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9207d477-5454-4b86-ac40-51a716b39da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MPS, may not work on some torch ops!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Found GPU: \", torch.cuda.device_count())\n",
    "    device = \"gpu\"\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"Found MPS, may not work on some torch ops!\" )\n",
    "    device = \"mps\"\n",
    "\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89914c03-339b-4286-a32d-76e3c3dfffc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contradict",
   "language": "python",
   "name": "contradict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
