{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04f0395-7e7d-4879-93da-fa0be5e7b1ea",
   "metadata": {},
   "source": [
    "# Contradictory sentences - baseline model\n",
    "Create a baseline model for contradiction classification\n",
    "\n",
    "Because this dataset is multi-lingual, we need to choose the best in class language model that is readily trainable (on kaggle TPUs?). One possibility is the [`XLM-RoBERTa`](https://huggingface.co/tomaarsen/span-marker-xlm-roberta-base-multinerd) model, but this model has fallen out of favor due to major tokenization limitations. The preferred model for multilanguage NER is this SpanMarker model using xlm-roberta-base as the underlying encoder, trained on the multinerd dataset: [`span-marker-xlm-roberta-base-multinerd`](https://huggingface.co/tomaarsen/span-marker-xlm-roberta-base-multinerd). The problem is that I wont want to be doing NER, I want to be doing sentence comparison.\n",
    "\n",
    "A reasonable starting point is just the base [`XLM-RoBERTa`](https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/xlm-roberta) model.\n",
    "\n",
    "This kaggle challenge was started as a reason to learn to use TPUs. You can use TPUs in PyTorch with the [`torch_xla`](https://pytorch.org/xla/release/2.0/index.html) package. See how to use it in this example kaggle code [here](https://www.kaggle.com/code/tanlikesmath/the-ultimate-pytorch-tpu-tutorial-jigsaw-xlm-r).  \n",
    "For now, we will stick with CPU/GPU. Double check Apple silicon MPS devices [[ref]](https://developer.apple.com/metal/pytorch/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717ed62d-39f5-44bd-b369-3e38749c5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from transformers import (\n",
    "    TrainingArguments, Trainer, \n",
    "    XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig)\n",
    "from datasets import DatasetDict\n",
    "\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "DATA_PATH = \"data\"\n",
    "WANDB_PROJECT = \"contradictory\"\n",
    "RAW_DATA_AT = \"contra_raw\"\n",
    "PROCESSED_DATA_AT = \"contra_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6066b84d-9a26-402a-b14f-6653ed60b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # random.seed(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9207d477-5454-4b86-ac40-51a716b39da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MPS, may not work on some torch ops!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Found GPU: \", torch.cuda.device_count())\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"Found MPS, may not work on some torch ops!\" )\n",
    "    device = \"mps\"\n",
    "\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5fe7c95-35fd-43a7-9598-950e12dc3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n",
    "    \"\"\"\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    tokenizer.enable_padding(max_length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830b58fa-5268-4f42-b934-dd56a5f972dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-base\"  # \"xlm-roberta-large\"\n",
    "\n",
    "BATCH_SIZE = 16 # hyperparameter, can iterate on this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "553e6fcc-ed15-45c6-af67-7402f13d387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(DATA_PATH, f\"contradiction-training-{str(int(time.time()))}\")\n",
    "\n",
    "train_config = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    max_steps=1,  # can change to 100\n",
    "    report_to=\"wandb\",  # enable logging to W&B\n",
    "    run_name=f\"{MODEL_NAME}-baseline\",  # name of the W&B run (optional)\n",
    "    label_smoothing_factor=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30e30b9-9e3e-4cca-9117-8ef37f67fd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmpesavento\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mpesavento/src/kaggle_comps/contradictory/notebooks/wandb/run-20230815_230955-3j6jnudy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mpesavento/contradictory/runs/3j6jnudy' target=\"_blank\">firm-salad-16</a></strong> to <a href='https://wandb.ai/mpesavento/contradictory' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mpesavento/contradictory' target=\"_blank\">https://wandb.ai/mpesavento/contradictory</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mpesavento/contradictory/runs/3j6jnudy' target=\"_blank\">https://wandb.ai/mpesavento/contradictory/runs/3j6jnudy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init wandb\n",
    "run = wandb.init(project=WANDB_PROJECT, entity=None, job_type=\"training\", config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3598a7ca-4a06-4648-a5b9-c147ed396d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "processed_data_at = run.use_artifact(f'{PROCESSED_DATA_AT}:latest')\n",
    "processed_dataset_dir = Path(processed_data_at.download())\n",
    "df = pd.read_csv(processed_dataset_dir / 'data_split.csv')\n",
    "\n",
    "# drop test for now, split in valid & train\n",
    "df = df[df.Stage != 'test'].reset_index(drop=True)\n",
    "df['is_valid'] = df.Stage == 'valid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec85a4a-cd31-42b8-af45-e79c3bdf5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d27bc8d-a35a-4723-a873-30e611eb4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df[df[\"is_valid\"]!=True])\n",
    "valid_dataset = Dataset.from_pandas(df[df[\"is_valid\"]])\n",
    "datasets = DatasetDict({\"train\": train_dataset, \"validation\": valid_dataset})\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63db7120-4629-4d7e-8c53-ced1e5fa3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_batch(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"premise\"], examples[\"hypothesis\"], \n",
    "                                   truncation=True, padding=True, return_tensors=\"pt\",)\n",
    "    return tokenized_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9ab4a8c-3f43-45da-bb8c-eb5afe84cdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e9b271252c43cf831976c7802ea17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9696 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57576831ad72483bac03bd0083fae4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function_batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f83c7f52-f403-4c85-a291-113cff95eae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> They look just as good as new.\" They cut them carefully and ripped away the oilskin.</s></s> The oilskin would be good for several months of use.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dd10005-7f0a-48e1-ab8a-1f2bb94a9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collator\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollator:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30c51164-436a-41b3-acb9-28011cb02e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original was from CustomRoberta here: https://www.kaggle.com/code/tanlikesmath/the-ultimate-pytorch-tpu-tutorial-jigsaw-xlm-r?scriptVersionId=37280514&cellId=27\n",
    "# this is an attempt to manually set up a sequence classifier. It looks like i'm not calculating the loss correctly, likely from \n",
    "# not interpreting the source code correctly\n",
    "# Using the XLMRobertaForSequenceClassification is the correct way to do this!\n",
    "# check source code for important differences: https://github.com/huggingface/transformers/blob/v4.17.0/src/transformers/models/roberta/modeling_roberta.py#L1162\n",
    "\n",
    "class XLMRobertaContradict(nn.Module):\n",
    "    def __init__(self, dropout=0.0):\n",
    "        super(XLMRobertaContradict, self).__init__()\n",
    "        self.num_labels = 3\n",
    "        self.dropout_pct = dropout\n",
    "        self.roberta = XLMRobertaModel.from_pretrained(MODEL_NAME, \n",
    "                                                       output_hidden_states=False, num_labels=self.num_labels)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_pct)\n",
    "        self.feats = self.roberta.pooler.dense.out_features\n",
    "        self.relu =  torch.nn.ReLU(inplace=True)\n",
    "        self.linear = nn.Linear(self.feats, self.num_labels)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                position_ids=None,\n",
    "                head_mask=None,\n",
    "                inputs_embeds=None,\n",
    "                # labels=None,\n",
    "               ):\n",
    "        x = self.roberta(input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       position_ids=position_ids,\n",
    "                       head_mask=head_mask,\n",
    "                       inputs_embeds=inputs_embeds)\n",
    "        # these have an unknown effect, idk what the hid_mix is doing. \n",
    "        # maybe blending the last hidden states to extend the output embedding?\n",
    "        # hidden_states = x[2]\n",
    "        # hmix = []\n",
    "        # for i in range(1, self.hid_mix + 1):\n",
    "        #     hmix.append(hidden_states[-i][:, 0].reshape((-1, 1, self.feats)))\n",
    "        # hmix_tensor = torch.cat(hmix, 1)\n",
    "        # mean_tensor = torch.mean(hmix_tensor, 1)\n",
    "        # pool_tensor = self.dropout(mean_tensor)\n",
    "        # return self.classifier(pool_tensor)\n",
    "        \n",
    "        # \n",
    "        # x = x.pooler_output  # get just the [CLS] token\n",
    "        x = x.last_hidden_state[:,0,:]\n",
    "        # x = self.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "        # import pdb; pdb.set_trace()\n",
    "        return x\n",
    "\n",
    "# model = XLMRobertaContradict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f2174d3-4fa0-429a-83ee-568f74c24479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "598d262d-c95f-4c6c-ad27-b87d94cdeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set up the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_config,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    # data_collator=DataCollator(tokenizer=tokenizer),\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f18eb81-f785-4ec5-90fb-9e6eeac0688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.506600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=0.5066074132919312, metrics={'train_runtime': 20.9575, 'train_samples_per_second': 0.382, 'train_steps_per_second': 0.048, 'total_flos': 1011333119040.0, 'train_loss': 0.5066074132919312, 'epoch': 0.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426998c-7996-4134-aeac-07e981f1f03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b35ed7-19ef-440b-bdf7-514150f031ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de386f0-2609-4b21-b3a7-a464addfe4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4a6d2-1de3-44a0-8b8a-2ca4380f8805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c25fbe-bf8c-46d3-aaa6-4d013e21d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up callbacks & metrics\n",
    "\n",
    "callbacks = [\n",
    "    SaveModelCallback(monitor='miou'),\n",
    "    WandbCallback(log_preds=False, log_model=True)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contradict",
   "language": "python",
   "name": "contradict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
