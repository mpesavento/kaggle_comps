{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04f0395-7e7d-4879-93da-fa0be5e7b1ea",
   "metadata": {},
   "source": [
    "# Contradictory sentences - baseline model\n",
    "Create a baseline model for contradiction classification\n",
    "\n",
    "Because this dataset is multi-lingual, we need to choose the best in class language model that is readily trainable (on kaggle TPUs?). One possibility is the [`XLM-RoBERTa`](https://huggingface.co/tomaarsen/span-marker-xlm-roberta-base-multinerd) model, but this model has fallen out of favor due to major tokenization limitations. The preferred model for multilanguage NER is this SpanMarker model using xlm-roberta-base as the underlying encoder, trained on the multinerd dataset: [`span-marker-xlm-roberta-base-multinerd`](https://huggingface.co/tomaarsen/span-marker-xlm-roberta-base-multinerd). The problem is that I wont want to be doing NER, I want to be doing sentence comparison.\n",
    "\n",
    "A reasonable starting point is just the base [`XLM-RoBERTa`](https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/xlm-roberta) model.\n",
    "\n",
    "This kaggle challenge was started as a reason to learn to use TPUs. You can use TPUs in PyTorch with the [`torch_xla`](https://pytorch.org/xla/release/2.0/index.html) package. See how to use it in this example kaggle code [here](https://www.kaggle.com/code/tanlikesmath/the-ultimate-pytorch-tpu-tutorial-jigsaw-xlm-r).  \n",
    "For now, we will stick with CPU/GPU. Double check Apple silicon MPS devices [[ref]](https://developer.apple.com/metal/pytorch/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d519535-90cf-47c2-94c8-3714ce3afabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "from types import SimpleNamespace  # a wrapper around a datadict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from transformers import XLMRobertaForSequenceClassification\n",
    "from transformers import (\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
    "    XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig)\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82179138-8b09-4bf2-a179-36afd3582340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH = \"data\"\n",
    "WANDB_PROJECT = \"contradictory\"\n",
    "RAW_DATA_AT = \"contra_raw\"\n",
    "PROCESSED_DATA_AT = \"contra_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9207d477-5454-4b86-ac40-51a716b39da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Found GPU: \", torch.cuda.device_count())\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"Found MPS, may not work on some torch ops!\" )\n",
    "    device = \"mps\"\n",
    "\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6eb06d3-a6d2-492b-b367-3282335d85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = SimpleNamespace(\n",
    "    framework=\"torch\",\n",
    "    batch_size=16,\n",
    "    num_epochs=1,\n",
    "    lr=1e-5,\n",
    "    arch=\"xlm-roberta-base\",\n",
    "    seed=SEED,\n",
    "    log_preds=True,\n",
    "    classifier_dropout=0.0,\n",
    "    id2label={0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"},\n",
    "    label2id={v:k for k,v in id2label.items()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553e6fcc-ed15-45c6-af67-7402f13d387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the HF accuracy fn\n",
    "accuracy_fn = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec85a4a-cd31-42b8-af45-e79c3bdf5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained(train_config.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6066b84d-9a26-402a-b14f-6653ed60b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # random.seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3598a7ca-4a06-4648-a5b9-c147ed396d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    processed_data_at = wandb.use_artifact(f'{PROCESSED_DATA_AT}:latest')\n",
    "    processed_dataset_dir = Path(processed_data_at.download())\n",
    "    return processed_dataset_dir\n",
    "\n",
    "def get_df(processed_dataset_dir, is_test=False):\n",
    "    df = pd.read_csv(processed_dataset_dir / 'data_split.csv')\n",
    "    if not is_test:\n",
    "        # drop test for now, split in valid & train\n",
    "        df = df[df.Stage != 'test'].reset_index(drop=True)\n",
    "        df['is_valid'] = df.Stage == 'valid'\n",
    "    else:\n",
    "        df = df[df.Stage == 'test'].reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f24ab4da-1717-4805-9ac7-32003e817ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_batch(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"premise\"], examples[\"hypothesis\"], \n",
    "                                   truncation=True, padding=True, return_tensors=\"pt\",)\n",
    "    return tokenized_examples\n",
    "\n",
    "def get_data(df):\n",
    "    \"\"\"\n",
    "    Load the data from df into a dataset\n",
    "    This is a bit more important if we are loading images/labels\n",
    "    \"\"\"\n",
    "    train_dataset = Dataset.from_pandas(df[df[\"is_valid\"]!=True])\n",
    "    valid_dataset = Dataset.from_pandas(df[df[\"is_valid\"]])\n",
    "    datasets = DatasetDict({\"train\": train_dataset, \"validation\": valid_dataset})\n",
    "    tokenized_datasets = datasets.map(tokenize_function_batch, batched=True)\n",
    "    return tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc681d9-8662-41f2-beb8-483cf6ea3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions_table(dataset, trainer, id2label):\n",
    "    \"\"\"Creates a wandb table with predictions and targets side by side\"\"\"\n",
    "    predictions = trainer.predict(dataset, metric_key_prefix=\"validate\")\n",
    "    X_pred = np.argmax(predictions.predictions, axis=1)\n",
    "    y_labels = predictions.label_ids\n",
    "    if not np.array_equal(y_labels, [dataset[i][\"label\"] for i in range(len(dataset))]):\n",
    "        raise ValueError(\"prediction labels do not match dataset labels\")\n",
    "    \n",
    "    col_names = [\"id\", \"premise\", \"hypothesis\", \"lang_abv\", \"label\", \"predict\"]\n",
    "\n",
    "    data_out = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        data_out.append({\n",
    "            col:sample[col] for col in col_names[:-1]})\n",
    "        data_out[-1][col_names[-1]] = X_pred[i]  # add the predict field\n",
    "    data_df = pd.DataFrame.from_records(data_out)\n",
    "\n",
    "    # add the positive match column, True if matched target label, false otherwise\n",
    "    data_df[\"is_correct\"] = (data_df[\"label\"]==data_df[\"predict\"]).astype(int)\n",
    "    \n",
    "    table = wandb.Table(data=data_df)\n",
    "    wandb.log({\"pred_table\":table})\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e74f53-1047-4713-86ae-664c7a6534b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_final_metrics(trainer):\n",
    "    scores = trainer.evaluate()\n",
    "    for k,v in scores.items():\n",
    "        wandb.summary[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6699eeb8-4a87-4e48-b524-2fe7b161ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    ent_ix = np.where(labels==label2id[\"entailment\"])[0]\n",
    "    neut_ix = np.where(labels==label2id[\"neutral\"])[0]\n",
    "    contra_ix = np.where(labels==label2id[\"contradiction\"])[0]\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_fn.compute(\n",
    "            predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"acc_entailment\": accuracy_fn.compute(\n",
    "            predictions=predictions[ent_ix], references=labels[ent_ix])[\"accuracy\"],\n",
    "        \"acc_neutral\": accuracy_fn.compute(\n",
    "            predictions=predictions[neut_ix], references=labels[neut_ix])[\"accuracy\"],\n",
    "        \"acc_contradiction\": accuracy_fn.compute(\n",
    "            predictions=predictions[contra_ix], references=labels[contra_ix])[\"accuracy\"],\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3685c35-d73e-4c13-9e08-1a9872267edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    seed_everything(SEED)\n",
    "    # init wandb\n",
    "    run = wandb.init(project=WANDB_PROJECT, entity=None, job_type=\"training\", config=config)\n",
    "\n",
    "    processed_dataset_dir = download_data()\n",
    "    df = get_df(processed_dataset_dir)\n",
    "    tokenized_datasets = get_data(df)  # more space in this for hyperparameters\n",
    "\n",
    "    config = wandb.config  # reload the instance config\n",
    "\n",
    "    num_labels = len(np.unique(tokenized_datasets['train'][\"label\"]))\n",
    "    # fixed model arch for now\n",
    "    xlm_roberta_config = XLMRobertaConfig.from_pretrained(config.arch)\n",
    "    # set dropout prob\n",
    "    # xlm_roberta_config.classifier_dropout = config.classifier_dropout\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(config.arch, num_labels=num_labels)\n",
    "\n",
    "    output_dir = os.path.join(DATA_PATH, f\"contradiction-training-{str(int(time.time()))}\")\n",
    "\n",
    "    trainer_config = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=config.lr,\n",
    "        num_train_epochs=config.num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=1,\n",
    "        report_to=\"wandb\",  # enable logging to W&B\n",
    "        # run_name=f\"{MODEL_NAME}-baseline\",  # name of the W&B run (optional)\n",
    "    )\n",
    "\n",
    "    # set up the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=trainer_config,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['validation'],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # train it!\n",
    "    model_trained = trainer.train()\n",
    "    \n",
    "    table = create_predictions_table(tokenized_datasets['validation'], trainer, id2label)\n",
    "    \n",
    "    \n",
    "    wandb.finish()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5d990-1a9c-4c91-a753-08ab66887f32",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58cf1c2b-fec3-46d7-bb3a-294d5b598083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmpesavento\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/kaggle_comps/contradictory/notebooks/wandb/run-20230822_210846-y3f3uq72</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mpesavento/contradictory/runs/y3f3uq72' target=\"_blank\">warm-energy-74</a></strong> to <a href='https://wandb.ai/mpesavento/contradictory' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mpesavento/contradictory' target=\"_blank\">https://wandb.ai/mpesavento/contradictory</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mpesavento/contradictory/runs/y3f3uq72' target=\"_blank\">https://wandb.ai/mpesavento/contradictory/runs/y3f3uq72</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f39dddcbd1141189e8d57a1033959ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9696 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63aa6e3d4f441bc9fbe3fc24a76da12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1212' max='1212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1212/1212 03:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Acc Entailment</th>\n",
       "      <th>Acc Neutral</th>\n",
       "      <th>Acc Contradiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.972319</td>\n",
       "      <td>0.541254</td>\n",
       "      <td>0.543062</td>\n",
       "      <td>0.579897</td>\n",
       "      <td>0.502463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1212it [00:00, 4014.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d4ac66bf6a458aa3f791fdd53001bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.824 MB of 0.824 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/acc_contradiction</td><td>▁</td></tr><tr><td>eval/acc_entailment</td><td>▁</td></tr><tr><td>eval/acc_neutral</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▃▃▄▂▄▃▃▃▃▃▂▃▃▂▂▃▃▃▄▂▃▂▄▄▂▁▅▃▃▄▃▁▄▃▂▁▂▄█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/acc_contradiction</td><td>0.50246</td></tr><tr><td>eval/acc_entailment</td><td>0.54306</td></tr><tr><td>eval/acc_neutral</td><td>0.5799</td></tr><tr><td>eval/accuracy</td><td>0.54125</td></tr><tr><td>eval/loss</td><td>0.97232</td></tr><tr><td>eval/runtime</td><td>8.4666</td></tr><tr><td>eval/samples_per_second</td><td>143.151</td></tr><tr><td>eval/steps_per_second</td><td>17.953</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>1212</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8647</td></tr><tr><td>train/total_flos</td><td>1216319885243568.0</td></tr><tr><td>train/train_loss</td><td>1.05958</td></tr><tr><td>train/train_runtime</td><td>219.6211</td></tr><tr><td>train/train_samples_per_second</td><td>44.149</td></tr><tr><td>train/train_steps_per_second</td><td>5.519</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-energy-74</strong> at: <a href='https://wandb.ai/mpesavento/contradictory/runs/y3f3uq72' target=\"_blank\">https://wandb.ai/mpesavento/contradictory/runs/y3f3uq72</a><br/> View job at <a href='https://wandb.ai/mpesavento/contradictory/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkxOTQyOTYx/version_details/v2' target=\"_blank\">https://wandb.ai/mpesavento/contradictory/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkxOTQyOTYx/version_details/v2</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230822_210846-y3f3uq72/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = train(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cb4ad5-b768-4f7d-81dc-a2fa493a289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cbac597c664528bea5b877e0d5d826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668295099952955, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/kaggle_comps/contradictory/notebooks/wandb/run-20230822_211251-gu7wyk45</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mpesavento/contradictory/runs/gu7wyk45' target=\"_blank\">winter-snowflake-77</a></strong> to <a href='https://wandb.ai/mpesavento/contradictory' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mpesavento/contradictory' target=\"_blank\">https://wandb.ai/mpesavento/contradictory</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mpesavento/contradictory/runs/gu7wyk45' target=\"_blank\">https://wandb.ai/mpesavento/contradictory/runs/gu7wyk45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=WANDB_PROJECT, entity=None, job_type=\"evaluation\", config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f6eb43-0543-4cbe-a52c-5e031cb8a3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9723190665245056,\n",
       " 'eval_accuracy': 0.5412541254125413,\n",
       " 'eval_acc_entailment': 0.5430622009569378,\n",
       " 'eval_acc_neutral': 0.5798969072164949,\n",
       " 'eval_acc_contradiction': 0.5024630541871922,\n",
       " 'eval_runtime': 8.4409,\n",
       " 'eval_samples_per_second': 143.586,\n",
       " 'eval_steps_per_second': 18.008,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23519424-c29b-469f-b3ca-64162f063d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contradict",
   "language": "python",
   "name": "contradict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
